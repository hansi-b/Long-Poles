{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def prettyPrint(procTestLists):\n",
    "    \"\"\"\n",
    "        Pretty-prints a list of lists of test assignments\n",
    "    \"\"\"\n",
    "    pWidth = 1+len(str(len(procTestLists)))\n",
    "    tWidth = 1+len(str(max(e for l in procTestLists for e in l)))\n",
    "    for pIdx, tList in enumerate(procTestLists):        \n",
    "        print(\"proc {:>{pWidth}} > {}\".format(pIdx, \" \".join(\"{:>{tWidth}}\".format(t, tWidth=tWidth) for t in tList),\n",
    "              pWidth=pWidth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The \"Long Pole\" Effect in Gradle's Test Execution\n",
    "\n",
    "When we assign a number of tests (with different runtimes) to multiple processors for parallel execution, the overall test runtime is that of the processor with the highest load as measured by the summed test execution times. Ideally, this approaches the quotient between total test runtime and number of processors. However, when one processor is assigned an unproportionally high load of tests, the overall runtime will depend on this processor: It will have to continue to work off tasks after all other processors have finshed, thus becoming the \"long pole\" in the runtime.\n",
    "\n",
    "This phenomenon has been [discussed for Gradle's parallel test execution](https://github.com/gradle/gradle/issues/2669)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scheduling\n",
    "\n",
    "Gradle currently uses a round-robin approach to evenly pre-allocate tests to multiple processors. This distribution is based solely on the order of the tests; it does not take into account size or other information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roundRobin(tests, procCount):\n",
    "    \"\"\" \n",
    "    Takes a list of test items and distributes them in a straight-forward round-robin\n",
    "    fashion amongst the number of given processors.\n",
    "    :return: a list of `procCount` lists L1 ...Lx, where each Li denotes the tests assigned\n",
    "             to processor #x.\n",
    "    \"\"\"\n",
    "    procs = [[] for _i in range(procCount)]\n",
    "\n",
    "    for tIdx, test in enumerate(tests):\n",
    "        pos = tIdx % procCount\n",
    "        procs[pos].append(test)\n",
    "    return procs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have 20 tests and 5 processors, they would be distributed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proc  0 >   0   5  10  15\n",
      "proc  1 >   1   6  11  16\n",
      "proc  2 >   2   7  12  17\n",
      "proc  3 >   3   8  13  18\n",
      "proc  4 >   4   9  14  19\n"
     ]
    }
   ],
   "source": [
    "prettyPrint(roundRobin(range(20), 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " So, if tests **0**, **5**, and **10** happen to take very long, processor **0** would become the long pole in this scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "\n",
    "Using generated test runtime distributions, we can simulate how they influence the overall runtime. In Gradle's own `build.gradle.kts`, we can modify the `allprojects` configuration to make the tests log their runtime:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```kotlin\n",
    "tasks.withType<Test> {\n",
    "        outputs.upToDateWhen { false }\n",
    "        addTestListener(object : TestListener {\n",
    "            override fun beforeSuite(suite: TestDescriptor) {}\n",
    "            override fun beforeTest(testDescriptor: TestDescriptor) {}\n",
    "            override fun afterTest(testDescriptor: TestDescriptor, result: TestResult) {\n",
    "            }\n",
    "            override fun afterSuite(suite: TestDescriptor, result: TestResult) {\n",
    "                val duration = result.endTime - result.startTime\n",
    "                println(\">>> $suite\\t${duration}\")\n",
    "            }\n",
    "        })\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting times for a few runs are collected in http://localhost:8888/lab/tree/gradle_test_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shifting Round Robin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shiftingRoundRobin(tests, procCount):\n",
    "    \"\"\" \n",
    "    Takes a list of test items and distributes them in a shifting round-robin\n",
    "    fashion amongst the number of given processors.\n",
    "    :return: a list of `procCount` lists L1 ...Lx, where each Li denotes the tests assigned\n",
    "             to processor #x.\n",
    "    \"\"\"\n",
    "    \n",
    "    procs = [[] for _i in range(procCount)]\n",
    "\n",
    "    for tIdx, test in enumerate(tests):\n",
    "        shift = (tIdx//procCount)%procCount\n",
    "        pos = (shift + tIdx) % procCount\n",
    "        procs[pos].append(test)\n",
    "    return procs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proc  0 >   0   5   7   9  14\n",
      "proc  1 >   1   3   8  10  12\n",
      "proc  2 >   2   4   6  11  13\n"
     ]
    }
   ],
   "source": [
    "res = shiftingRoundRobin(range(15), 3)\n",
    "prettyPr(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
